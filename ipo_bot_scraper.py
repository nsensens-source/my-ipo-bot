import os
import asyncio
from playwright.async_api import async_playwright
from supabase import create_client

# 1. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Supabase
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

async def scrape_nasdaq_ipo():
    async with async_playwright() as p:
        # ‡πÄ‡∏õ‡∏¥‡∏î Browser ‡πÅ‡∏ö‡∏ö Headless (‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠)
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        print("üåê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤ Nasdaq IPO Calendar...")
        try:
            # ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤ IPO Calendar ‡∏Ç‡∏≠‡∏á Nasdaq
            await page.goto("https://www.nasdaq.com/market-activity/ipos", wait_until="networkidle", timeout=60000)
            
            # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à
            await page.wait_for_selector(".market-calendar-table__table")

            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Ticker ‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Selector ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡πá‡∏ö Nasdaq
            tickers = await page.locator(".market-calendar-table__column--symbol").all_inner_texts()
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠ Header ‡∏≠‡∏≠‡∏Å
            clean_tickers = [t.strip() for t in tickers if t.strip() and t != "Symbol"]
            
            print(f"‚úÖ ‡∏û‡∏ö‡∏´‡∏∏‡πâ‡∏ô IPO ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(clean_tickers)} ‡∏ï‡∏±‡∏ß: {clean_tickers}")
            return clean_tickers

        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Scrape: {e}")
            return []
        finally:
            await browser.close()

def update_database(tickers):
    for ticker in tickers:
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏´‡∏∏‡πâ‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Database ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
        check = supabase.table("ipo_trades").select("ticker").eq("ticker", ticker).execute()
        
        if not check.data:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏∏‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ 'watching'
            # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ base_high ‡πÄ‡∏õ‡πá‡∏ô 0 ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏õ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏≠‡∏ó‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏¢‡∏´‡∏≤‡πÉ‡∏´‡πâ
            new_data = {
                "ticker": ticker,
                "status": "watching",
                "base_high": 0,  
                "highest_price": 0,
                "buy_price": 0
            }
            supabase.table("ipo_trades").insert(new_data).execute()
            print(f"üÜï ‡πÄ‡∏û‡∏¥‡πà‡∏° {ticker} ‡πÄ‡∏Ç‡πâ‡∏≤ Watchlist ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        else:
            print(f"‚ûñ {ticker} ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡πâ‡∏ß")

async def main():
    found_tickers = await scrape_nasdaq_ipo()
    if found_tickers:
        update_database(found_tickers)

if __name__ == "__main__":
    asyncio.run(main())
